{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hieti36R0PWj"
      },
      "source": [
        "# Lead Score - Case Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PEY6VXi0PWk"
      },
      "source": [
        "## Problem Statement\n",
        "An X Education need help to select the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company requires us to build a model wherein you need to assign a lead score to each of the leads such that the customers with higher lead score have a higher conversion chance and the customers with lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%. <br>\n",
        "## Goals and Objectives\n",
        "There are quite a few goals for this case study.\n",
        "- Build a logistic regression model to assign a lead score between 0 and 100 to each of the leads which can be used by the company to target potential leads. A higher score would mean that the lead is hot, i.e. is most likely to convert whereas a lower score would mean that the lead is cold and will mostly not get converted.\n",
        "- There are some more problems presented by the company which your model should be able to adjust to if the company's requirement changes in the future so you will need to handle these as well. These problems are provided in a separate doc file. Please fill it based on the logistic regression model you got in the first step. Also, make sure you include this in your final PPT where you'll make recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zoHDNHE0PWl"
      },
      "source": [
        "___All the outcomes and understandings are written in <font color= green> GREEN</font>___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mkxMYV_L0PWl"
      },
      "outputs": [],
      "source": [
        "# Supress Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#Importing required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNUK48cc0PWl"
      },
      "source": [
        "# 1 : Loading and Cleaning Data\n",
        "\n",
        "##  1.1  Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "fX6jLRlQ0PWl",
        "outputId": "4714d2b7-e356-4095-fbc7-558c8ec919b9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'F:\\\\data science\\\\predictive analysis\\\\assignment group\\\\Lead Scoring Assignment\\\\Leads.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-040d113c0b44>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the data using Pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F:\\\\data science\\\\predictive analysis\\\\assignment group\\\\Lead Scoring Assignment\\\\Leads.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\data science\\\\predictive analysis\\\\assignment group\\\\Lead Scoring Assignment\\\\Leads.csv'"
          ]
        }
      ],
      "source": [
        "# Loading the data using Pandas\n",
        "df = pd.read_csv('F:\\\\data science\\\\predictive analysis\\\\assignment group\\\\Lead Scoring Assignment\\\\Leads.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH_3h44N0PWm"
      },
      "source": [
        "## 1.2 Inspect the dataframe\n",
        "This helps to give a good idea of the dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HYexSDp30PWm"
      },
      "outputs": [],
      "source": [
        "# The .info() code gives almost the entire information that needs to be inspected, so let's start from there\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pI6NPze30PWm"
      },
      "outputs": [],
      "source": [
        "#To get the idea of how the table looks like we can use .head() or .tail() command\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5TUl_PXz0PWn"
      },
      "outputs": [],
      "source": [
        "# The .shape code gives the no. of rows and columns\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0tlKazBU0PWn"
      },
      "outputs": [],
      "source": [
        "#To get an idea of the numeric values, use .describe()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0-LepWv0PWn"
      },
      "source": [
        "## 1.3 Cleaning the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "un7-ifS80PWn"
      },
      "outputs": [],
      "source": [
        "# Converting all the values to lower case\n",
        "df = df.applymap(lambda s:s.lower() if type(s) == str else s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LvV0gRj70PWn"
      },
      "outputs": [],
      "source": [
        "# Replacing 'Select' with NaN (Since it means no option is selected)\n",
        "df = df.replace('select',np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Yu1mdZO30PWn"
      },
      "outputs": [],
      "source": [
        "# Checking if there are columns with one unique value since it won't affect our analysis\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H__ins5_0PWo"
      },
      "outputs": [],
      "source": [
        "# Dropping unique valued columns\n",
        "df1= df.drop(['Magazine','Receive More Updates About Our Courses','I agree to pay the amount through cheque','Get updates on DM Content','Update me on Supply Chain Content'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GBWlIqZE0PWo"
      },
      "outputs": [],
      "source": [
        "# Checking the percentage of missing values\n",
        "round(100*(df1.isnull().sum()/len(df1.index)), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "R3q0KWg_0PWo"
      },
      "outputs": [],
      "source": [
        "# Removing all the columns that are no required and have 35% null values\n",
        "df2 = df1.drop(['Asymmetrique Profile Index','Asymmetrique Activity Index','Asymmetrique Activity Score','Asymmetrique Profile Score','Lead Profile','Tags','Lead Quality','How did you hear about X Education','City','Lead Number'],axis=1)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Of8hy9iu0PWo"
      },
      "outputs": [],
      "source": [
        "# Rechecking the percentage of missing values\n",
        "round(100*(df2.isnull().sum()/len(df2.index)), 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vzN78uL0PWo"
      },
      "source": [
        "<font color= green>___There is a huge value of null variables in 4 columns as seen above. But removing the rows with the null value will cost us a lot of data and they are important columns. So, instead we are going to replace the NaN values with 'not provided'. This way we have all the data and almost no null values. In case these come up in the model, it will be of no use and we can drop it off then.___</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aPlwzEWa0PWp"
      },
      "outputs": [],
      "source": [
        "df2['Specialization'] = df2['Specialization'].fillna('not provided')\n",
        "df2['What matters most to you in choosing a course'] = df2['What matters most to you in choosing a course'].fillna('not provided')\n",
        "df2['Country'] = df2['Country'].fillna('not provided')\n",
        "df2['What is your current occupation'] = df2['What is your current occupation'].fillna('not provided')\n",
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KXoCDZRI0PWp"
      },
      "outputs": [],
      "source": [
        "# Rechecking the percentage of missing values\n",
        "round(100*(df2.isnull().sum()/len(df2.index)), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "K86QCs3c0PWp"
      },
      "outputs": [],
      "source": [
        "df2[\"Country\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0WyI0h5N0PWp"
      },
      "outputs": [],
      "source": [
        "def slots(x):\n",
        "    category = \"\"\n",
        "    if x == \"india\":\n",
        "        category = \"india\"\n",
        "    elif x == \"not provided\":\n",
        "        category = \"not provided\"\n",
        "    else:\n",
        "        category = \"outside india\"\n",
        "    return category\n",
        "\n",
        "df2['Country'] = df2.apply(lambda x:slots(x['Country']), axis = 1)\n",
        "df2['Country'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wKCsMjNt0PWp"
      },
      "outputs": [],
      "source": [
        "# Rechecking the percentage of missing values\n",
        "round(100*(df2.isnull().sum()/len(df2.index)), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jtfDSGKV0PWp"
      },
      "outputs": [],
      "source": [
        "# Checking the percent of lose if the null values are removed\n",
        "round(100*(sum(df2.isnull().sum(axis=1) > 1)/df2.shape[0]),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tmlTljdn0PWp"
      },
      "outputs": [],
      "source": [
        "df3 = df2[df2.isnull().sum(axis=1) <1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2JkmV8Yo0PWq"
      },
      "outputs": [],
      "source": [
        "# Code for checking number of rows left in percent\n",
        "round(100*(df3.shape[0])/(df.shape[0]),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JWAsh5Dm0PWq"
      },
      "outputs": [],
      "source": [
        "# Rechecking the percentage of missing values\n",
        "round(100*(df3.isnull().sum()/len(df3.index)), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TnMwbTCO0PWq"
      },
      "outputs": [],
      "source": [
        "# To familiarize all the categorical values\n",
        "for column in df3:\n",
        "    print(df3[column].astype('category').value_counts())\n",
        "    print('----------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cOhKgdiG0PWq"
      },
      "outputs": [],
      "source": [
        "# Removing Id values since they are unique for everyone\n",
        "df_final = df3.drop('Prospect ID',1)\n",
        "df_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TMIebE50PWq"
      },
      "source": [
        "## 2. EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QkBvP7o0PWq"
      },
      "source": [
        "### 2.1. Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbDI5blv0PWq"
      },
      "source": [
        "#### 2.1.1. Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DRch629Q0PWr"
      },
      "outputs": [],
      "source": [
        "df_final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A64gfuXY0PWr"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (20,40))\n",
        "\n",
        "plt.subplot(6,2,1)\n",
        "sns.countplot(df_final['Lead Origin'])\n",
        "plt.title('Lead Origin')\n",
        "\n",
        "plt.subplot(6,2,2)\n",
        "sns.countplot(df_final['Do Not Email'])\n",
        "plt.title('Do Not Email')\n",
        "\n",
        "plt.subplot(6,2,3)\n",
        "sns.countplot(df_final['Do Not Call'])\n",
        "plt.title('Do Not Call')\n",
        "\n",
        "plt.subplot(6,2,4)\n",
        "sns.countplot(df_final['Country'])\n",
        "plt.title('Country')\n",
        "\n",
        "plt.subplot(6,2,5)\n",
        "sns.countplot(df_final['Search'])\n",
        "plt.title('Search')\n",
        "\n",
        "plt.subplot(6,2,6)\n",
        "sns.countplot(df_final['Newspaper Article'])\n",
        "plt.title('Newspaper Article')\n",
        "\n",
        "plt.subplot(6,2,7)\n",
        "sns.countplot(df_final['X Education Forums'])\n",
        "plt.title('X Education Forums')\n",
        "\n",
        "plt.subplot(6,2,8)\n",
        "sns.countplot(df_final['Newspaper'])\n",
        "plt.title('Newspaper')\n",
        "\n",
        "plt.subplot(6,2,9)\n",
        "sns.countplot(df_final['Digital Advertisement'])\n",
        "plt.title('Digital Advertisement')\n",
        "\n",
        "plt.subplot(6,2,10)\n",
        "sns.countplot(df_final['Through Recommendations'])\n",
        "plt.title('Through Recommendations')\n",
        "\n",
        "plt.subplot(6,2,11)\n",
        "sns.countplot(df_final['A free copy of Mastering The Interview'])\n",
        "plt.title('A free copy of Mastering The Interview')\n",
        "\n",
        "plt.subplot(6,2,12)\n",
        "sns.countplot(df_final['Last Notable Activity']).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Last Notable Activity')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6TcRGm3d0PWr"
      },
      "outputs": [],
      "source": [
        "sns.countplot(df_final['Lead Source']).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Lead Source')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8NR4v4Zr0PWr"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (20,30))\n",
        "plt.subplot(2,2,1)\n",
        "sns.countplot(df_final['Specialization']).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Specialization')\n",
        "plt.subplot(2,2,2)\n",
        "sns.countplot(df_final['What is your current occupation']).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Current Occupation')\n",
        "plt.subplot(2,2,3)\n",
        "sns.countplot(df_final['What matters most to you in choosing a course']).tick_params(axis='x', rotation = 90)\n",
        "plt.title('What matters most to you in choosing a course')\n",
        "plt.subplot(2,2,4)\n",
        "sns.countplot(df_final['Last Activity']).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Last Activity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gB-m5XUG0PWr"
      },
      "outputs": [],
      "source": [
        "sns.countplot(df['Converted'])\n",
        "plt.title('Converted(\"Y variable\")')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLbmVUaT0PWy"
      },
      "source": [
        "#### 2.1.1. Numerical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yid-Vtjg0PWy"
      },
      "outputs": [],
      "source": [
        "df_final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WSGyxp630PWy"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "plt.subplot(221)\n",
        "plt.hist(df_final['TotalVisits'], bins = 200)\n",
        "plt.title('Total Visits')\n",
        "plt.xlim(0,25)\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.hist(df_final['Total Time Spent on Website'], bins = 10)\n",
        "plt.title('Total Time Spent on Website')\n",
        "\n",
        "plt.subplot(223)\n",
        "plt.hist(df_final['Page Views Per Visit'], bins = 20)\n",
        "plt.title('Page Views Per Visit')\n",
        "plt.xlim(0,20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF_2ZaAU0PWz"
      },
      "source": [
        "### 2.1. Relating all the categorical variables to Converted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XfXEmL_w0PWz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='Lead Origin', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Lead Origin')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='Lead Source', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Lead Source')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XfnOjS-u0PWz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='Do Not Email', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Do Not Email')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='Do Not Call', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Do Not Call')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ahMgV80J0PWz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='Last Activity', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Last Activity')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='Country', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Country')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Gc9fFSHr0PWz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='Specialization', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Specialization')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='What is your current occupation', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('What is your current occupation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UYTtjZEk0PWz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='What matters most to you in choosing a course', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('What matters most to you in choosing a course')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='Search', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Search')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Vwt6bENp0PW0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='Newspaper Article', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Newspaper Article')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='X Education Forums', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('X Education Forums')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dd9f8bRr0PW0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='Newspaper', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Newspaper')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='Digital Advertisement', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Digital Advertisement')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Uf9Z-cfW0PW0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='Through Recommendations', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Through Recommendations')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='A free copy of Mastering The Interview', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('A free copy of Mastering The Interview')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "W13eYBt10PW0"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='Last Notable Activity', hue='Converted', data= df_final).tick_params(axis='x', rotation = 90)\n",
        "plt.title('Last Notable Activity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fuDOSgj-0PW0"
      },
      "outputs": [],
      "source": [
        "# To check the correlation among varibles\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(df_final.corr())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyiGJer00PW0"
      },
      "source": [
        "<font color= green>___It is understandable from the above EDA that there are many elements that have very little data and so will be of less relevance to our analysis.___</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ccfHa9d70PW1"
      },
      "outputs": [],
      "source": [
        "numeric = df_final[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']]\n",
        "numeric.describe(percentiles=[0.25,0.5,0.75,0.9,0.99])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFPO-tXH0PW1"
      },
      "source": [
        "<font color= green>___There aren't any major outliers, so moving on to analysis___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhge6hdD0PW1"
      },
      "source": [
        "## 3. Dummy Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9dIBU_Gq0PW1"
      },
      "outputs": [],
      "source": [
        "df_final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bABgLK4i0PW1"
      },
      "outputs": [],
      "source": [
        "df_final.loc[:, df_final.dtypes == 'object'].columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "S_DZuYiM0PW1"
      },
      "outputs": [],
      "source": [
        "# Create dummy variables using the 'get_dummies'\n",
        "dummy = pd.get_dummies(df_final[['Lead Origin','Specialization' ,'Lead Source', 'Do Not Email', 'Last Activity', 'What is your current occupation','A free copy of Mastering The Interview', 'Last Notable Activity']], drop_first=True)\n",
        "# Add the results to the master dataframe\n",
        "df_final_dum = pd.concat([df_final, dummy], axis=1)\n",
        "df_final_dum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tNXUodB20PW2"
      },
      "outputs": [],
      "source": [
        "df_final_dum = df_final_dum.drop(['What is your current occupation_not provided','Lead Origin', 'Lead Source', 'Do Not Email', 'Do Not Call','Last Activity', 'Country', 'Specialization', 'Specialization_not provided','What is your current occupation','What matters most to you in choosing a course', 'Search','Newspaper Article', 'X Education Forums', 'Newspaper','Digital Advertisement', 'Through Recommendations','A free copy of Mastering The Interview', 'Last Notable Activity'], 1)\n",
        "df_final_dum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilTOH8FJ0PW2"
      },
      "source": [
        "## 4. Test-Train Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Sj_XdcuW0PW2"
      },
      "outputs": [],
      "source": [
        "# Import the required library\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "a3OIeFHG0PW2"
      },
      "outputs": [],
      "source": [
        "X = df_final_dum.drop(['Converted'], 1)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Az5p188u0PW2"
      },
      "outputs": [],
      "source": [
        "# Putting the target variable in y\n",
        "y = df_final_dum['Converted']\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Rva00v_V0PW2"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into 70% and 30% for train and test respectively\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nXCjLoyZ0PW2"
      },
      "outputs": [],
      "source": [
        "# Import MinMax scaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Scale the three numeric features\n",
        "scaler = MinMaxScaler()\n",
        "X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] = scaler.fit_transform(X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cUDrcWiE0PW2"
      },
      "outputs": [],
      "source": [
        "# To check the correlation among varibles\n",
        "plt.figure(figsize=(20,30))\n",
        "sns.heatmap(X_train.corr())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn5Yfr050PW3"
      },
      "source": [
        "<font color= green>___Since there are a lot of variables it is difficult to drop variable. We'll do it after RFE___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgO0iOH80PW3"
      },
      "source": [
        "## 5. Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yb8qf9sI0PW3"
      },
      "outputs": [],
      "source": [
        "# Import 'LogisticRegression'\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eiTeZxiW0PW3"
      },
      "outputs": [],
      "source": [
        "# Import RFE\n",
        "from sklearn.feature_selection import RFE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SlX-EuWG0PW3"
      },
      "outputs": [],
      "source": [
        "# Running RFE with 15 variables as output\n",
        "rfe = RFE(logreg, 15)\n",
        "rfe = rfe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7I8dLBtz0PW3"
      },
      "outputs": [],
      "source": [
        "# Features that have been selected by RFE\n",
        "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dyLUpaQ40PW3"
      },
      "outputs": [],
      "source": [
        "# Put all the columns selected by RFE in the variable 'col'\n",
        "col = X_train.columns[rfe.support_]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izCLDs8_0PW4"
      },
      "source": [
        "<font color= green>___All the variables selected by RFE, next statistics part (p-values and the VIFs).___</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7DWhGa1j0PW4"
      },
      "outputs": [],
      "source": [
        "# Selecting columns selected by RFE\n",
        "X_train = X_train[col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9sRoYWaK0PW4"
      },
      "outputs": [],
      "source": [
        "# Importing statsmodels\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "j97lH07W0PW4"
      },
      "outputs": [],
      "source": [
        "X_train_sm = sm.add_constant(X_train)\n",
        "logm1 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
        "res = logm1.fit()\n",
        "res.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8JiFRSWM0PW4"
      },
      "outputs": [],
      "source": [
        "# Importing 'variance_inflation_factor'\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TCOM8A6h0PW4"
      },
      "outputs": [],
      "source": [
        "# Make a VIF dataframe for all the variables present\n",
        "vif = pd.DataFrame()\n",
        "vif['Features'] = X_train.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
        "vif['VIF'] = round(vif['VIF'], 2)\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "vif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oc-PG1y0PW4"
      },
      "source": [
        "<font color= green>___The VIF values seem fine but the p-values aren't. So removing 'Last Notable Activity had a phone conversation'___</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VCNKK8Uq0PW4"
      },
      "outputs": [],
      "source": [
        "X_train.drop('Last Notable Activity_had a phone conversation', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Mw-t-T650PW5"
      },
      "outputs": [],
      "source": [
        "# Refit the model with the new set of features\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "logm2 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
        "res = logm2.fit()\n",
        "res.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KTgzr8X80PW5"
      },
      "outputs": [],
      "source": [
        "# Make a VIF dataframe for all the variables present\n",
        "vif = pd.DataFrame()\n",
        "vif['Features'] = X_train.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
        "vif['VIF'] = round(vif['VIF'], 2)\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "vif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA8F_XNa0PW5"
      },
      "source": [
        "<font color= green>___The VIF values seem fine but the p-values aren't. So removing 'What is your current occupation housewife'___</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FT7SalEq0PW5"
      },
      "outputs": [],
      "source": [
        "X_train.drop('What is your current occupation_housewife', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Xb8W0d650PW5"
      },
      "outputs": [],
      "source": [
        "# Refit the model with the new set of features\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "logm3 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
        "res = logm3.fit()\n",
        "res.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8Qbbaz-n0PW5"
      },
      "outputs": [],
      "source": [
        "# Make a VIF dataframe for all the variables present\n",
        "vif = pd.DataFrame()\n",
        "vif['Features'] = X_train.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
        "vif['VIF'] = round(vif['VIF'], 2)\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "vif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHf0mmI-0PW5"
      },
      "source": [
        "<font color= green>___The VIF values seem fine but the p-values aren't. So removing 'What is your current occupation other'___</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nNUmakmU0PW5"
      },
      "outputs": [],
      "source": [
        "X_train.drop('What is your current occupation_other', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JyII2Sdi0PW6"
      },
      "outputs": [],
      "source": [
        "# Refit the model with the new set of features\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "logm4 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
        "res = logm4.fit()\n",
        "res.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eIuwU9Fx0PW6"
      },
      "outputs": [],
      "source": [
        "# Make a VIF dataframe for all the variables present\n",
        "vif = pd.DataFrame()\n",
        "vif['Features'] = X_train.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
        "vif['VIF'] = round(vif['VIF'], 2)\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "vif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D08tIroJ0PW6"
      },
      "source": [
        "<font color= green>___All the VIF values are good and all the p-values are below 0.05. So we can fix model.___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXMOZf6a0PW6"
      },
      "source": [
        "## 6. Creating Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JuUTCENR0PW6"
      },
      "outputs": [],
      "source": [
        "# Predicting the probabilities on the train set\n",
        "y_train_pred = res.predict(X_train_sm)\n",
        "y_train_pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "S-wAlujO0PW6"
      },
      "outputs": [],
      "source": [
        "# Reshaping to an array\n",
        "y_train_pred = y_train_pred.values.reshape(-1)\n",
        "y_train_pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xxbXnJQo0PW6"
      },
      "outputs": [],
      "source": [
        "# Data frame with given convertion rate and probablity of predicted ones\n",
        "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
        "y_train_pred_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k8nwB5it0PW6"
      },
      "outputs": [],
      "source": [
        "# Substituting 0 or 1 with the cut off as 0.5\n",
        "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
        "y_train_pred_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suim8Iqb0PW7"
      },
      "source": [
        "## 7. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k8z4IhsI0PW7"
      },
      "outputs": [],
      "source": [
        "# Importing metrics from sklearn for evaluation\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ytOflM3m0PW7"
      },
      "outputs": [],
      "source": [
        "# Creating confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
        "confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NOklsr_H0PW7"
      },
      "outputs": [],
      "source": [
        "# Predicted     not_churn    churn\n",
        "# Actual\n",
        "# not_churn        3403       492\n",
        "# churn             729      1727"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jGHgh8M00PW7"
      },
      "outputs": [],
      "source": [
        "# Check the overall accuracy\n",
        "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.Predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urJkBhlJ0PW8"
      },
      "source": [
        "<font color= green>___That's around 81% accuracy with is a very good value___</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yMwXr4tg0PW8"
      },
      "outputs": [],
      "source": [
        "# Substituting the value of true positive\n",
        "TP = confusion[1,1]\n",
        "# Substituting the value of true negatives\n",
        "TN = confusion[0,0]\n",
        "# Substituting the value of false positives\n",
        "FP = confusion[0,1]\n",
        "# Substituting the value of false negatives\n",
        "FN = confusion[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OdQodYmy0PW8"
      },
      "outputs": [],
      "source": [
        "# Calculating the sensitivity\n",
        "TP/(TP+FN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3Gb_Ghvo0PW8"
      },
      "outputs": [],
      "source": [
        "# Calculating the specificity\n",
        "TN/(TN+FP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaS-SPWh0PW8"
      },
      "source": [
        "<font color= green>___With the current cut off as 0.5 we have around 81% accuracy, sensitivity of around 70% and specificity of around 87%.___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTV3JxeK0PW8"
      },
      "source": [
        "## 7. Optimise Cut off (ROC Curve)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yteEKDQy0PW8"
      },
      "source": [
        "The previous cut off was randomely selected. Now to find the optimum one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ylXqAUDS0PW8"
      },
      "outputs": [],
      "source": [
        "# ROC function\n",
        "def draw_roc( actual, probs ):\n",
        "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
        "                                              drop_intermediate = False )\n",
        "    auc_score = metrics.roc_auc_score( actual, probs )\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-1k0cz070PW9"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob, drop_intermediate = False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2y1d67X60PW9"
      },
      "outputs": [],
      "source": [
        "# Call the ROC function\n",
        "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJNzgTIl0PW9"
      },
      "source": [
        "<font color= green>___The area under ROC curve is 0.87 which is a very good value.___</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Upu2eTqw0PW9"
      },
      "outputs": [],
      "source": [
        "# Creating columns with different probability cutoffs\n",
        "numbers = [float(x)/10 for x in range(10)]\n",
        "for i in numbers:\n",
        "    y_train_pred_final[i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\n",
        "y_train_pred_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OYGtgXLE0PW9"
      },
      "outputs": [],
      "source": [
        "# Creating a dataframe to see the values of accuracy, sensitivity, and specificity at different values of probabiity cutoffs\n",
        "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
        "# Making confusing matrix to find values of sensitivity, accurace and specificity for each level of probablity\n",
        "from sklearn.metrics import confusion_matrix\n",
        "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
        "    total1=sum(sum(cm1))\n",
        "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "\n",
        "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
        "cutoff_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Yn7N5WDr0PW9"
      },
      "outputs": [],
      "source": [
        "# Plotting it\n",
        "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOgr9RVE0PW9"
      },
      "source": [
        "<font color= green>___From the graph it is visible that the optimal cut off is at 0.35.___</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bg8_edUz0PW-"
      },
      "outputs": [],
      "source": [
        "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.35 else 0)\n",
        "y_train_pred_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "25VqsW6P0PW-"
      },
      "outputs": [],
      "source": [
        "# Check the overall accuracy\n",
        "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QKCKVuVd0PW-"
      },
      "outputs": [],
      "source": [
        "# Creating confusion matrix\n",
        "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
        "confusion2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "31juvsjD0PW-"
      },
      "outputs": [],
      "source": [
        "# Substituting the value of true positive\n",
        "TP = confusion2[1,1]\n",
        "# Substituting the value of true negatives\n",
        "TN = confusion2[0,0]\n",
        "# Substituting the value of false positives\n",
        "FP = confusion2[0,1]\n",
        "# Substituting the value of false negatives\n",
        "FN = confusion2[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HvJhmRO40PW-"
      },
      "outputs": [],
      "source": [
        "# Calculating the sensitivity\n",
        "TP/(TP+FN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G9qr3q1l0PW-"
      },
      "outputs": [],
      "source": [
        "# Calculating the specificity\n",
        "TN/(TN+FP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlKcTjpE0PW-"
      },
      "source": [
        "<font color= green>___With the current cut off as 0.35 we have accuracy, sensitivity and specificity of around 80%.___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9JS6ZaB0PW_"
      },
      "source": [
        "## 8. Prediction on Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1d-wlQqW0PW_"
      },
      "outputs": [],
      "source": [
        "# Scaling numeric values\n",
        "X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] = scaler.transform(X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b5vGwfNZ0PW_"
      },
      "outputs": [],
      "source": [
        "# Substituting all the columns in the final train model\n",
        "col = X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "19RWd1Bs0PW_"
      },
      "outputs": [],
      "source": [
        "# Select the columns in X_train for X_test as well\n",
        "X_test = X_test[col]\n",
        "# Add a constant to X_test\n",
        "X_test_sm = sm.add_constant(X_test[col])\n",
        "X_test_sm\n",
        "X_test_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-Q0nH1Mz0PW_"
      },
      "outputs": [],
      "source": [
        "# Storing prediction of test set in the variable 'y_test_pred'\n",
        "y_test_pred = res.predict(X_test_sm)\n",
        "# Coverting it to df\n",
        "y_pred_df = pd.DataFrame(y_test_pred)\n",
        "# Converting y_test to dataframe\n",
        "y_test_df = pd.DataFrame(y_test)\n",
        "# Remove index for both dataframes to append them side by side\n",
        "y_pred_df.reset_index(drop=True, inplace=True)\n",
        "y_test_df.reset_index(drop=True, inplace=True)\n",
        "# Append y_test_df and y_pred_df\n",
        "y_pred_final = pd.concat([y_test_df, y_pred_df],axis=1)\n",
        "# Renaming column\n",
        "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
        "y_pred_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uGlKeEmI0PW_"
      },
      "outputs": [],
      "source": [
        "# Making prediction using cut off 0.35\n",
        "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.35 else 0)\n",
        "y_pred_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mJfjGoKX0PW_"
      },
      "outputs": [],
      "source": [
        "# Check the overall accuracy\n",
        "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QwFS_1ys0PW_"
      },
      "outputs": [],
      "source": [
        "# Creating confusion matrix\n",
        "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
        "confusion2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "soj-VSIu0PXA"
      },
      "outputs": [],
      "source": [
        "# Substituting the value of true positive\n",
        "TP = confusion2[1,1]\n",
        "# Substituting the value of true negatives\n",
        "TN = confusion2[0,0]\n",
        "# Substituting the value of false positives\n",
        "FP = confusion2[0,1]\n",
        "# Substituting the value of false negatives\n",
        "FN = confusion2[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Pc-FZ0rA0PXA"
      },
      "outputs": [],
      "source": [
        "# Calculating the sensitivity\n",
        "TP/(TP+FN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "o780DBAv0PXA"
      },
      "outputs": [],
      "source": [
        "# Calculating the specificity\n",
        "TN/(TN+FP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcozkVsg0PXA"
      },
      "source": [
        "<font color= green>___With the current cut off as 0.35 we have accuracy, sensitivity and specificity of around 80%.___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQI2wciy0PXA"
      },
      "source": [
        "## 9. Precision-Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2-ZL3fbc0PXA"
      },
      "outputs": [],
      "source": [
        "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
        "confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g0gYZDhl0PXA"
      },
      "outputs": [],
      "source": [
        "# Precision = TP / TP + FP\n",
        "confusion[1,1]/(confusion[0,1]+confusion[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XEwLgAbq0PXA"
      },
      "outputs": [],
      "source": [
        "#Recall = TP / TP + FN\n",
        "confusion[1,1]/(confusion[1,0]+confusion[1,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wGv0grB0PXB"
      },
      "source": [
        "<font color= green>___With the current cut off as 0.35 we have Precision around 78% and Recall around 70%___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHEfVlkG0PXB"
      },
      "source": [
        "### 9.1. Precision and recall tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "koKDJ-bj0PXB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "glEfQCcU0PXB"
      },
      "outputs": [],
      "source": [
        "y_train_pred_final.Converted, y_train_pred_final.Predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZAG-Ibeh0PXB"
      },
      "outputs": [],
      "source": [
        "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H6wZt_qM0PXB"
      },
      "outputs": [],
      "source": [
        "plt.plot(thresholds, p[:-1], \"g-\")\n",
        "plt.plot(thresholds, r[:-1], \"r-\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NkG-ZB2C0PXB"
      },
      "outputs": [],
      "source": [
        "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.41 else 0)\n",
        "y_train_pred_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "R2UeI8jQ0PXB"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sBQps8-z0PXC"
      },
      "outputs": [],
      "source": [
        "# Creating confusion matrix again\n",
        "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
        "confusion2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VKxQtVOn0PXC"
      },
      "outputs": [],
      "source": [
        "# Substituting the value of true positive\n",
        "TP = confusion2[1,1]\n",
        "# Substituting the value of true negatives\n",
        "TN = confusion2[0,0]\n",
        "# Substituting the value of false positives\n",
        "FP = confusion2[0,1]\n",
        "# Substituting the value of false negatives\n",
        "FN = confusion2[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QdPQ37l_0PXC"
      },
      "outputs": [],
      "source": [
        "# Precision = TP / TP + FP\n",
        "TP / (TP + FP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "12tB3XAm0PXC"
      },
      "outputs": [],
      "source": [
        "#Recall = TP / TP + FN\n",
        "TP / (TP + FN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDnco3aE0PXC"
      },
      "source": [
        "<font color= green>___With the current cut off as 0.41 we have Precision around 74% and Recall around 76%___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjrFsPkN0PXC"
      },
      "source": [
        "## 10. Prediction on Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KrHQ1GrV0PXC"
      },
      "outputs": [],
      "source": [
        "# Storing prediction of test set in the variable 'y_test_pred'\n",
        "y_test_pred = res.predict(X_test_sm)\n",
        "# Coverting it to df\n",
        "y_pred_df = pd.DataFrame(y_test_pred)\n",
        "# Converting y_test to dataframe\n",
        "y_test_df = pd.DataFrame(y_test)\n",
        "# Remove index for both dataframes to append them side by side\n",
        "y_pred_df.reset_index(drop=True, inplace=True)\n",
        "y_test_df.reset_index(drop=True, inplace=True)\n",
        "# Append y_test_df and y_pred_df\n",
        "y_pred_final = pd.concat([y_test_df, y_pred_df],axis=1)\n",
        "# Renaming column\n",
        "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
        "y_pred_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3QPiHPGi0PXC"
      },
      "outputs": [],
      "source": [
        "# Making prediction using cut off 0.41\n",
        "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.41 else 0)\n",
        "y_pred_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IpGGzQAA0PXD"
      },
      "outputs": [],
      "source": [
        "# Check the overall accuracy\n",
        "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-d7CHMES0PXD"
      },
      "outputs": [],
      "source": [
        "# Creating confusion matrix\n",
        "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
        "confusion2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "89CM8MLb0PXD"
      },
      "outputs": [],
      "source": [
        "# Substituting the value of true positive\n",
        "TP = confusion2[1,1]\n",
        "# Substituting the value of true negatives\n",
        "TN = confusion2[0,0]\n",
        "# Substituting the value of false positives\n",
        "FP = confusion2[0,1]\n",
        "# Substituting the value of false negatives\n",
        "FN = confusion2[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IX07ZaPg0PXD"
      },
      "outputs": [],
      "source": [
        "# Precision = TP / TP + FP\n",
        "TP / (TP + FP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yaxzWtuZ0PXD"
      },
      "outputs": [],
      "source": [
        "#Recall = TP / TP + FN\n",
        "TP / (TP + FN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA2BPHzs0PXD"
      },
      "source": [
        "<font color= green>___With the current cut off as 0.41 we have Precision around 73% and Recall around 75%___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZATMwSi0PXD"
      },
      "source": [
        "## Conclusion\n",
        "It was found that the variables that mattered the most in the potential buyers are (In descending order) :\n",
        "1.\tThe total time spend on the Website.\n",
        "2.\tTotal number of visits.\n",
        "3.\tWhen the lead source was: <br>\n",
        "a.\tGoogle<br>\n",
        "b.\tDirect traffic<br>\n",
        "c.\tOrganic search<br>\n",
        "d.\tWelingak website<br>\n",
        "4.\tWhen the last activity was:<br>\n",
        "a.\tSMS<br>\n",
        "b.\tOlark chat conversation<br>\n",
        "5.\tWhen the lead origin is Lead add format.\n",
        "6.\tWhen their current occupation is as a working professional.<br>\n",
        "Keeping these in mind the X Education can flourish as they have a very high chance to get almost all the potential buyers to change their mind and buy their courses."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}